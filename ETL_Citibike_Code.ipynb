{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pip setuptools\n",
        "!pip install azure-storage-blob pandas\n",
        "\n",
        "import pandas as pd\n",
        "from azure.storage.blob import BlobServiceClient\n",
        "import io  # Import io for BytesIO\n",
        "\n",
        "import pandas as pd\n",
        "from azure.storage.blob import BlobServiceClient\n",
        "from io import BytesIO  # Ensure BytesIO is imported"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rnGKgKMT6koi",
        "outputId": "d9ca817b-f404-42a9-bd71-15c65724f7f1",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (24.3.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (75.6.0)\n",
            "Requirement already satisfied: azure-storage-blob in /usr/local/lib/python3.10/dist-packages (12.24.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: azure-core>=1.30.0 in /usr/local/lib/python3.10/dist-packages (from azure-storage-blob) (1.32.0)\n",
            "Requirement already satisfied: cryptography>=2.1.4 in /usr/local/lib/python3.10/dist-packages (from azure-storage-blob) (43.0.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from azure-storage-blob) (4.12.2)\n",
            "Requirement already satisfied: isodate>=0.6.1 in /usr/local/lib/python3.10/dist-packages (from azure-storage-blob) (0.7.2)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: requests>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from azure-core>=1.30.0->azure-storage-blob) (2.32.3)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from azure-core>=1.30.0->azure-storage-blob) (1.16.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=2.1.4->azure-storage-blob) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=2.1.4->azure-storage-blob) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.21.0->azure-core>=1.30.0->azure-storage-blob) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.21.0->azure-core>=1.30.0->azure-storage-blob) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.21.0->azure-core>=1.30.0->azure-storage-blob) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.21.0->azure-core>=1.30.0->azure-storage-blob) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Connecting to Azure"
      ],
      "metadata": {
        "id": "ugvSNnrA6o32"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Azure Blob Storage connection details\n",
        "connection_string = \"DefaultEndpointsProtocol=https;AccountName=citibikestorageproj;AccountKey=psNYQilyqmQOGt89lwlc14aIoI6ttYuDuPolHTED0cNlxLCVRlJJpEjyFdaAItvvjC6pNcG3kD6l+AStRrGuPQ==;EndpointSuffix=core.windows.net\"\n",
        "container_name = \"rawdata\"  # Ensure this container exists in your Azure Blob Storage\n",
        "file_name = \"202407-citibike-tripdata_1.csv\"  # Ensure this file exists in the container\n",
        "\n",
        "try:\n",
        "    # Connect to Azure Blob Storage\n",
        "    blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n",
        "    blob_client = blob_service_client.get_blob_client(container=container_name, blob=file_name)\n",
        "\n",
        "    # Download the CSV file as a DataFrame\n",
        "    downloaded_blob = blob_client.download_blob().readall()\n",
        "    data = pd.read_csv(BytesIO(downloaded_blob))  # Use io.BytesIO to read the blob\n",
        "\n",
        "    print(data.head())  # Preview the loaded data\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")\n",
        "\n",
        "import pandas as pd\n",
        "from azure.storage.blob import BlobServiceClient\n",
        "from io import BytesIO\n",
        "\n",
        "# Azure Blob Storage connection details\n",
        "connection_string = \"DefaultEndpointsProtocol=https;AccountName=citibikestorageproj;AccountKey=psNYQilyqmQOGt89lwlc14aIoI6ttYuDuPolHTED0cNlxLCVRlJJpEjyFdaAItvvjC6pNcG3kD6l+AStRrGuPQ==;EndpointSuffix=core.windows.net\"\n",
        "container_name = \"rawdata\"  # Your container name\n",
        "file_name = \"202407-citibike-tripdata_1.csv\"  # Your file name\n",
        "\n",
        "# Step 1: Connect to Azure Blob Storage and Download Data\n",
        "try:\n",
        "    blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n",
        "    blob_client = blob_service_client.get_blob_client(container=container_name, blob=file_name)\n",
        "\n",
        "    # Check if blob exists\n",
        "    if blob_client.exists():\n",
        "        print(\"Blob exists. Downloading...\")\n",
        "        downloaded_blob = blob_client.download_blob().readall()\n",
        "        print(\"Blob downloaded successfully.\")\n",
        "    else:\n",
        "        print(f\"Blob '{file_name}' not found in container '{container_name}'.\")\n",
        "        exit()\n",
        "\n",
        "    # Load data into a pandas DataFrame\n",
        "    try:\n",
        "        data = pd.read_csv(BytesIO(downloaded_blob))\n",
        "        print(\"Data loaded into DataFrame successfully.\")\n",
        "        print(data.head())\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading blob content: {e}\")\n",
        "        exit()\n",
        "except Exception as e:\n",
        "    print(f\"Error downloading or reading blob: {e}\")\n",
        "    exit()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "H9XfGNdHuRws",
        "outputId": "5baf1180-68b4-4095-d3c5-171033ad8690"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-cf520fb7f921>:13: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  data = pd.read_csv(BytesIO(downloaded_blob))  # Use io.BytesIO to read the blob\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Unnamed: 0           ride_id  rideable_type               started_at  \\\n",
            "0           0  A3818B07E831C033  electric_bike  2024-07-01 21:00:55.640   \n",
            "1           1  40B46D3F898A6CA4  electric_bike  2024-07-09 18:28:39.551   \n",
            "2           2  33683B345D08C2BC  electric_bike  2024-07-14 17:10:28.899   \n",
            "3           3  B213C077CE572EBD  electric_bike  2024-07-01 11:37:06.440   \n",
            "4           4  E42FF50D966A009B  electric_bike  2024-07-05 16:55:59.093   \n",
            "\n",
            "                  ended_at      start_station_name start_station_id  \\\n",
            "0  2024-07-01 21:07:43.553         W 24 St & 7 Ave          6257.03   \n",
            "1  2024-07-09 18:46:43.854   Park Pl & Buffalo Ave          3999.06   \n",
            "2  2024-07-14 17:27:59.917         E 48 St & 5 Ave          6626.01   \n",
            "3  2024-07-01 11:42:02.259  Melrose Ave & E 154 St          7918.12   \n",
            "4  2024-07-05 16:59:41.250         W 24 St & 7 Ave          6257.03   \n",
            "\n",
            "             end_station_name end_station_id  start_lat  start_lng    end_lat  \\\n",
            "0            W 20 St & 10 Ave        6306.01  40.744784 -73.995524  40.745686   \n",
            "1      Irving Ave & Harman St        4856.05  40.671992 -73.925502  40.701080   \n",
            "2       E 43 St & Madison Ave        6551.11  40.757246 -73.978059  40.753547   \n",
            "3        Wales Ave & E 147 St        7751.05  40.819665 -73.916111  40.811314   \n",
            "4  Greenwich Ave & Charles St        5914.08  40.744817 -73.995416  40.735238   \n",
            "\n",
            "     end_lng member_casual  \n",
            "0 -74.005141        member  \n",
            "1 -73.917900        member  \n",
            "2 -73.978966        casual  \n",
            "3 -73.907729        member  \n",
            "4 -74.000271        member  \n",
            "Blob exists. Downloading...\n",
            "Blob downloaded successfully.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-cf520fb7f921>:45: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  data = pd.read_csv(BytesIO(downloaded_blob))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded into DataFrame successfully.\n",
            "   Unnamed: 0           ride_id  rideable_type               started_at  \\\n",
            "0           0  A3818B07E831C033  electric_bike  2024-07-01 21:00:55.640   \n",
            "1           1  40B46D3F898A6CA4  electric_bike  2024-07-09 18:28:39.551   \n",
            "2           2  33683B345D08C2BC  electric_bike  2024-07-14 17:10:28.899   \n",
            "3           3  B213C077CE572EBD  electric_bike  2024-07-01 11:37:06.440   \n",
            "4           4  E42FF50D966A009B  electric_bike  2024-07-05 16:55:59.093   \n",
            "\n",
            "                  ended_at      start_station_name start_station_id  \\\n",
            "0  2024-07-01 21:07:43.553         W 24 St & 7 Ave          6257.03   \n",
            "1  2024-07-09 18:46:43.854   Park Pl & Buffalo Ave          3999.06   \n",
            "2  2024-07-14 17:27:59.917         E 48 St & 5 Ave          6626.01   \n",
            "3  2024-07-01 11:42:02.259  Melrose Ave & E 154 St          7918.12   \n",
            "4  2024-07-05 16:59:41.250         W 24 St & 7 Ave          6257.03   \n",
            "\n",
            "             end_station_name end_station_id  start_lat  start_lng    end_lat  \\\n",
            "0            W 20 St & 10 Ave        6306.01  40.744784 -73.995524  40.745686   \n",
            "1      Irving Ave & Harman St        4856.05  40.671992 -73.925502  40.701080   \n",
            "2       E 43 St & Madison Ave        6551.11  40.757246 -73.978059  40.753547   \n",
            "3        Wales Ave & E 147 St        7751.05  40.819665 -73.916111  40.811314   \n",
            "4  Greenwich Ave & Charles St        5914.08  40.744817 -73.995416  40.735238   \n",
            "\n",
            "     end_lng member_casual  \n",
            "0 -74.005141        member  \n",
            "1 -73.917900        member  \n",
            "2 -73.978966        casual  \n",
            "3 -73.907729        member  \n",
            "4 -74.000271        member  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perform Transformation\n"
      ],
      "metadata": {
        "id": "TNxUhrtG6tKS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    # Unified Date Format\n",
        "    data['start_time'] = pd.to_datetime(data['started_at'], errors='coerce').dt.strftime('%Y-%m-%d')\n",
        "    data['end_time'] = pd.to_datetime(data['ended_at'], errors='coerce').dt.strftime('%Y-%m-%d')\n",
        "\n",
        "    # Splitting Dates into Multiple Units\n",
        "    data['start_year'] = pd.to_datetime(data['started_at'], errors='coerce').dt.year\n",
        "    data['start_quarter'] = pd.to_datetime(data['started_at'], errors='coerce').dt.quarter\n",
        "    data['start_month'] = pd.to_datetime(data['started_at'], errors='coerce').dt.month\n",
        "    data['start_day'] = pd.to_datetime(data['started_at'], errors='coerce').dt.day\n",
        "    data['start_hour'] = pd.to_datetime(data['started_at'], errors='coerce').dt.hour\n",
        "\n",
        "    data['end_year'] = pd.to_datetime(data['ended_at'], errors='coerce').dt.year\n",
        "    data['end_quarter'] = pd.to_datetime(data['ended_at'], errors='coerce').dt.quarter\n",
        "    data['end_month'] = pd.to_datetime(data['ended_at'], errors='coerce').dt.month\n",
        "    data['end_day'] = pd.to_datetime(data['ended_at'], errors='coerce').dt.day\n",
        "    data['end_hour'] = pd.to_datetime(data['ended_at'], errors='coerce').dt.hour\n",
        "\n",
        "    # Removing NULL Values\n",
        "    data.dropna(subset=['started_at', 'ended_at'], inplace=True)\n",
        "\n",
        "    # Removing Duplicate Rows\n",
        "    data.drop_duplicates(inplace=True)\n",
        "\n",
        "    # Adding New Columns (Trip Duration in Minutes)\n",
        "    data['trip_duration_minutes'] = (\n",
        "        pd.to_datetime(data['ended_at'], errors='coerce') - pd.to_datetime(data['started_at'], errors='coerce')\n",
        "    ).dt.total_seconds() / 60\n",
        "\n",
        "    # Summing Columns (Latitude + Longitude)\n",
        "    data['start_lat_lng_sum'] = data['start_lat'] + data['start_lng']\n",
        "    data['end_lat_lng_sum'] = data['end_lat'] + data['end_lng']\n",
        "\n",
        "    print(\"Transformations applied successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error during transformations: {e}\")\n",
        "    exit()\n",
        "\n",
        "# Step 3: Create Data Mapping for Data Dictionary\n",
        "try:\n",
        "    data_mapping = pd.DataFrame({\n",
        "        'Field Name': data.columns,\n",
        "        'Data Type': [data[col].dtype for col in data.columns],\n",
        "        'Description': ['Description for ' + col for col in data.columns],\n",
        "        'Source Column': data.columns,\n",
        "        'Destination Column': data.columns\n",
        "    })\n",
        "\n",
        "    # Save Transformed Data and Data Mapping\n",
        "    data.to_csv('transformed_data.csv', index=False)  # Save the transformed data\n",
        "    data_mapping.to_csv('data_mapping.csv', index=False)  # Save the data dictionary\n",
        "\n",
        "    print(\"Transformation complete. Files saved: 'transformed_data.csv' and 'data_mapping.csv'.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error saving files: {e}\")"
      ],
      "metadata": {
        "id": "SBfR0Ous6xM0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccff3e16-71a8-493e-dc33-8ab6e73e378a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transformations applied successfully.\n",
            "Transformation complete. Files saved: 'transformed_data.csv' and 'data_mapping.csv'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving and uploading Transformed Data\n"
      ],
      "metadata": {
        "id": "p2aKStue6y6u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from io import BytesIO\n",
        "from azure.storage.blob import BlobServiceClient\n",
        "\n",
        "# Save transformed data to a CSV in memory\n",
        "try:\n",
        "    # Create an in-memory bytes buffer\n",
        "    output = BytesIO()\n",
        "    data.to_csv(output, index=False, encoding='utf-8')  # Save data to the buffer\n",
        "    output.seek(0)  # Reset the buffer position to the beginning\n",
        "\n",
        "    # Connect to Azure Blob Storage\n",
        "    blob_client = blob_service_client.get_blob_client(container=container_name, blob=\"transformed_citibike_data.csv\")\n",
        "\n",
        "    # Upload the CSV to Azure Blob Storage\n",
        "    blob_client.upload_blob(output, overwrite=True)\n",
        "    print(\"Transformed data uploaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error uploading transformed data: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4JlpPbiE_xFk",
        "outputId": "f38e2d1a-42e1-423a-b822-bc6b326b36dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transformed data uploaded successfully.\n"
          ]
        }
      ]
    }
  ]
}